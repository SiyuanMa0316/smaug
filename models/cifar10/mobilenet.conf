// MobileNet on CIFAR10
//
// This gets to 85% in 100 epochs.

network {
  name = "mobilenets"
  input_rows = 32
  input_cols = 32
  input_height = 3

  layer block0_conv_dw {
    type = DEPTHWISE_CONVOLUTION
    convolution_param {
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer block0_bn0 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block0_conv_pw {
    type = POINTWISE_CONVOLUTION
    convolution_param {
      num_output = 32
      kernel_size = 1
      stride = 1
    }
  }

  layer block0_bn1 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block1_conv_dw {
    type = DEPTHWISE_CONVOLUTION
    convolution_param {
      kernel_size = 3
      stride = 2
      padding = SAME
    }
  }

  layer block1_bn0 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block1_conv_pw {
    type = POINTWISE_CONVOLUTION
    convolution_param {
      num_output = 64
      kernel_size = 1
      stride = 1
    }
  }

  layer block1_bn1 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block2_conv_dw {
    type = DEPTHWISE_CONVOLUTION
    convolution_param {
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer block2_bn0 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block2_conv_pw {
    type = POINTWISE_CONVOLUTION
    convolution_param {
      num_output = 128
      kernel_size = 1
      stride = 1
    }
  }

  layer block2_bn1 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block3_conv_dw {
    type = DEPTHWISE_CONVOLUTION
    convolution_param {
      kernel_size = 3
      stride = 2
      padding = SAME
    }
  }

  layer block3_bn0 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block3_conv_pw {
    type = POINTWISE_CONVOLUTION
    convolution_param {
      num_output = 256
      kernel_size = 1
      stride = 1
    }
  }

  layer block3_bn1 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block4_conv_dw {
    type = DEPTHWISE_CONVOLUTION
    convolution_param {
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer block4_bn0 {
    type = BATCH_NORM
    activation = RELU
  }

  layer block4_conv_pw {
    type = POINTWISE_CONVOLUTION
    convolution_param {
      num_output = 256
      kernel_size = 1
      stride = 1
    }
  }

  layer block4_bn1 {
    type = BATCH_NORM
    activation = RELU
  }

  layer pool {
    type = POOLING
    pooling_param {
      pool = AVG
      size = 4
      stride = 4
    }
  }

  layer dense {
    type = INNER_PRODUCT
    inner_product_param {
      num_output = 10
    }
  }
}

device {
  cpu_default_offload = DMA
  cpu_activation_func_offload = ACP
  cpu_pooling_offload = DMA
  use_hw_activation_func = false
  use_hw_pooling = true
  use_hw_batch_norm = true
}
