// CIFAR10, with a VGG-like model.

network {
  name = "cifar10-vgg"
  input_rows = 32
  input_cols = 32
  input_height = 3

  layer conv0 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 64
      pad = 0
      stride = 1
    }
  }

  layer conv1 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 64
      pad = 1
      stride = 1
    }
  }

  layer pool0 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv2 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 128
      pad = 1
      stride = 1
    }
  }

  layer conv3 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 128
      pad = 1
      stride = 1
    }
  }

  layer pool1 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv4 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 256
      pad = 1
      stride = 1
    }
  }

  layer conv5 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 256
      pad = 1
      stride = 1
    }
  }

  layer conv6 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 256
      pad = 1
      stride = 1
    }
  }

  layer pool2 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv7 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 512
      pad = 1
      stride = 1
    }
  }

  layer conv8 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 512
      pad = 1
      stride = 1
    }
  }

  layer conv9 {
    type = CONVOLUTION
    activation = "RELU"
    convolution_param {
      kernel_size = 3
      num_output = 512
      pad = 1
      stride = 1
    }
  }

  layer pool3 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer fc0 {
    type = INNER_PRODUCT
    activation = "RELU"
    inner_product_param {
      num_output = 512
    }
  }

  layer fc1 {
    type = INNER_PRODUCT
    inner_product_param {
      num_output = 10
    }
  }
}
