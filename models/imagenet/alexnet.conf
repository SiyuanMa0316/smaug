// AlexNet CNN.
//
// Naturally, there is no LRN.

network {
  name = "alexnet"
  input_x = 224
  input_y = 224
  input_z = 3

  layer conv0 {
    type = CONVOLUTIION
    activation = RELU
    convolution_param {
      kernel_size = 11
      stride = 4
      num_output = 96
      pad = 5
    }
  }

  // TODO: This would produce an error since the input size is odd and the size
  // is even.
  layer pool1 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv2 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      kernel_size = 3
      num_output = 256
      stride = 1
      pad = 1
    }
  }

  layer pool3 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv4 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      kernel_size = 3
      num_output = 384
      stride = 1
      pad = 1
    }
  }

  layer conv5 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      kernel_size = 3
      num_output = 384
      stride = 1
      pad = 1
    }
  }

  layer conv6 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      kernel_size = 3
      num_output = 256
      stride = 1
      pad = 1
    }
  }

  layer pool7 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer fc8 {
    type = INNER_PRODUCT
    activation = RELU
    inner_product_param {
      num_output = 4096
    }
  }

  layer fc9 {
    type = INNER_PRODUCT
    activation = RELU
    inner_product_param {
      num_output = 4096
    }
  }

  layer fc10 {
    type = INNER_PRODUCT
    inner_product_param {
      num_output = 1000
    }
  }
}
