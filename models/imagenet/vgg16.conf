// VGG-16.

network {
  name = "vgg16"
  input_rows = 224
  input_cols = 224
  input_height = 3

  layer conv0 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 64
      padding = SAME
      kernel_size = 3
    }
  }

  layer conv1 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 64
      padding = SAME
      kernel_size = 3
    }
  }

  layer pool2 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv3 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 128
      padding = SAME
      kernel_size = 3
    }
  }

  layer conv4 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 128
      padding = SAME
      kernel_size = 3
    }
  }

  layer pool5 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv6 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 256
      padding = SAME
      kernel_size = 3
    }
  }

  layer conv7 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 256
      padding = SAME
      kernel_size = 3
    }
  }

  layer conv8 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 256
      padding = VALID
      kernel_size = 1
    }
  }

  layer pool9 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv10 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 3
    }
  }

  layer conv11 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 3
    }
  }

  layer conv12 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 1
    }
  }

  layer pool13 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer conv14 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 3
    }
  }

  layer conv15 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 3
    }
  }

  layer conv16 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 512
      padding = VALID
      kernel_size = 1
    }
  }

  layer pool17 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }


  layer fc18 {
    type = INNER_PRODUCT
    activation = RELU
    inner_product_param {
      num_output = 4096
    }
  }

  layer fc19 {
    type = INNER_PRODUCT
    activation = RELU
    inner_product_param {
      num_output = 4096
    }
  }

  layer fc20 {
    type = INNER_PRODUCT
    inner_product_param {
      num_output = 1000
    }
  }
}
